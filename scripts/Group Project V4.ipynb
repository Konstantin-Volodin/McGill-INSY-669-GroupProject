{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed7827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Documents\\Projects\\McGill\\McGill-INSY-669-GroupProject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Konstantin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# WEB SCRAPING\n",
    "import requests #for scrapping\n",
    "from bs4 import BeautifulSoup #for scrapping\n",
    "\n",
    "# GENERIC\n",
    "import pandas as pd #data transformation\n",
    "import itertools #combinations\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# TEXT WRANGLING\n",
    "import nltk # tokenize\n",
    "from nltk import pos_tag, sent_tokenize, wordpunct_tokenize # tokenize\n",
    "from nltk.corpus import stopwords #stopwords\n",
    "import string # for punctuation\n",
    "from collections import Counter # to get frequency of words\n",
    "from nltk.stem import WordNetLemmatizer # to lemmatize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# INITIALIZATION\n",
    "nltk.download('omw-1.4')\n",
    "directory = os.path.realpath(os.path.join(os.getcwd(),\"..\"))\n",
    "os.chdir(directory)\n",
    "print(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c994ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT PARSING\n",
    "def parse_comment(soup, company):\n",
    "    \"\"\"returns a comment dictionary given a comment soup\n",
    "    \n",
    "    INPUTS: beautiful soup object containing a comment\n",
    "    OUTPUT: dictionary with relevant comment fields\n",
    "    \"\"\"\n",
    "    comment={}\n",
    "\n",
    "    # review id\n",
    "    comment['id'] = soup['id']\n",
    "\n",
    "    # title of the review\n",
    "    title_text = soup.find(\"a\", class_=\"reviewLink\")\n",
    "    comment['Title_Review'] = title_text.text\n",
    "\n",
    "    # stars\n",
    "    stars_text = soup.find(\"span\", attrs={\"class\": \"ratingNumber mr-xsm\"})\n",
    "    comment['Stars'] = float(stars_text.text)\n",
    "\n",
    "    # company name\n",
    "    comment['Company_name'] = company\n",
    "\n",
    "    # recommend\n",
    "    elem = soup.find('div', class_=\"recommends\").contents[0].find('svg', class_=\"SVGInline-svg\")\n",
    "    if 'css-hcqxoa-svg' in elem['class']: comment['Recommend'] = 'positive'\n",
    "    elif 'css-1kiw93k-svg' in elem['class']: comment['Recommend'] = 'negative'\n",
    "    elif 'css-10xv9lv-svg' in elem['class']: comment['Recommend'] = 'neutral'\n",
    "    else: comment['Recommend'] = 'error'\n",
    "\n",
    "    # ceo approval\n",
    "    elem = soup.find('div', class_=\"recommends\").contents[1].find('svg', class_=\"SVGInline-svg\")\n",
    "    if 'css-hcqxoa-svg' in elem['class']: comment['CEO_approval'] = 'positive'\n",
    "    elif 'css-1kiw93k-svg' in elem['class']: comment['CEO_approval'] = 'negative'\n",
    "    elif 'css-10xv9lv-svg' in elem['class']: comment['CEO_approval'] = 'neutral'\n",
    "    else: comment['CEO_approval'] = 'error'\n",
    "\n",
    "    # business outlook\n",
    "    elem = soup.find('div', class_=\"recommends\").contents[2].find('svg', class_=\"SVGInline-svg\")\n",
    "    if 'css-hcqxoa-svg' in elem['class']: comment['Business_outlook'] = 'positive'\n",
    "    elif 'css-1kiw93k-svg' in elem['class']: comment['Business_outlook'] = 'negative'\n",
    "    elif 'css-10xv9lv-svg' in elem['class']: comment['Business_outlook'] = 'neutral'\n",
    "    else: comment['Business_outlook'] = 'error'\n",
    "\n",
    "    # pros\n",
    "    pros_text = soup.find(\"span\", attrs={\"data-test\": \"pros\"})\n",
    "    comment['Pros'] = pros_text.text\n",
    "\n",
    "    # cons\n",
    "    cons_text = soup.find(\"span\", attrs={\"data-test\": \"cons\"}) \n",
    "    comment['Cons'] = cons_text.text\n",
    "\n",
    "    # employee seniority\n",
    "    seniority_text = soup.find(\"span\", attrs={\"class\": \"pt-xsm pt-md-0 css-1qxtz39 eg4psks0\"})\n",
    "    comment['Employee_seniority'] = seniority_text.text\n",
    "\n",
    "    # location\n",
    "    elem = soup.find('span', class_='common__EiReviewDetailsStyle__newUiJobLine')\n",
    "    location = elem.text.split('-')[1].strip().split(\" \")\n",
    "    loc_true = False\n",
    "    for word in location:\n",
    "        if '\\xa0in' in word: \n",
    "            loc_true = True\n",
    "\n",
    "    if loc_true: comment['Location'] = \" \".join(location[-2:])\n",
    "    else:  comment['Location'] = None\n",
    "\n",
    "    # date\n",
    "    elem = soup.find('span', class_='common__EiReviewDetailsStyle__newUiJobLine')\n",
    "    comment['Date'] = elem.text.split('-')[0].strip()\n",
    "\n",
    "    return (comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8cb3465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ  https://www.glassdoor.ca/Reviews/Amazon-Reviews-E6036_P0.htm?filter.iso3Language=eng\n",
      "READ  https://www.glassdoor.ca/Reviews/Amazon-Reviews-E6036_P1.htm?filter.iso3Language=eng\n",
      "READ  https://www.glassdoor.ca/Reviews/Amazon-Reviews-E6036_P2.htm?filter.iso3Language=eng\n",
      "READ  https://www.glassdoor.ca/Reviews/Amazon-Reviews-E6036_P3.htm?filter.iso3Language=eng\n",
      "READ  https://www.glassdoor.ca/Reviews/Amazon-Reviews-E6036_P4.htm?filter.iso3Language=eng\n"
     ]
    }
   ],
   "source": [
    "# THIS MODULE DOWNLOADS / READS DATA FOR A SPECIFIC COMPANY\n",
    "COMPANY = \"Amazon\"\n",
    "comments = []\n",
    "\n",
    "for i in range(5):\n",
    "    url = \"https://www.glassdoor.ca/Reviews/Amazon-Reviews-E6036_P\"+str(i)+\".htm?filter.iso3Language=eng\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    page_comments = soup.find_all('li', class_='empReview')\n",
    "    comments.extend(page_comments)\n",
    "    print('READ ', url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6a034dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS MODULE CLEANS THE COMMENT DATA\n",
    "comments_clean = []\n",
    "for comment in comments:\n",
    "    comments_clean.append(parse_comment(comment, COMPANY))\n",
    "\n",
    "df_clean = pd.DataFrame.from_records(comments_clean)\n",
    "df_clean.to_csv(f'data/{COMPANY}_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e42bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insy-669-group-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e8724c141d7f45219f25bfd8638fe4af3cf76718fc8f6848186446036c8778f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
